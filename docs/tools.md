# üîß LLM Tools

Despite their impressive capabilities, LLMs have inherent limitations that prevent them from functioning as fully autonomous agents. These limitations fall into three categories: temporal, interaction, and functional.

### üï∞Ô∏è Temporal limitation

They cannot access information beyond their training data or retrieve data that changes in real time. This makes them unreliable for tasks requiring current knowledge, such as answering questions about recent events or live market conditions.

### ‚û°Ô∏è Interaction limitation

They cannot directly influence the external world. While they can generate text describing an action, they cannot actually book a flight, send an email, or control a device.

### üßÆ Functional limitations 

In specialized domains certain tasks requiring precise computation, code execution, or media generation often exceed what language models can reliably accomplish through text prediction alone. 

Tools can address each of these limitations.

**Temporal tools**augment information to bridge the temporal gap by injecting up-to-date knowledge into the agent's context. They can be used to extend the LLM's awareness beyond its training cutoff date. These can include tooling to allow your Agent web access, real-time APIs such as weather or stock prices, or custom databases.

**Action-executing tools** overcome the interaction limitation by enabling agents to affect the real world. Examples include booking systems for hotels and flights, communication tools for emails and calendar management, automation tools for document generation, and IoT controllers for smart devices. These tools trigger Actions and receive Observations in return, forming a feedback loop with the environment.

**Domain-specialised tools** address functional limitations by handling tasks where LLMs fall short. Calculators, code interpreters, format converters, image generators, and voice synthesis engines allow hybrid problem-solving‚Äîcombining the LLM's reasoning with reliable execution in specialised domains.

Common LLM providers such as OpenAI and Anthropic already offer some tooling, for example OpenAI's web search feature and Anthropic's web search tool. These tools are available for us to use immediately without any development effort. The trade off is that they cannot be easily modified or extended, and they can be changed at the providers discretion. LLM providers will list the available non-custom, tools available to you. 

## Custom tools

We are going to focus on building custom tooling for our learning and to provide understanding to help debug and build fully bespoke Agents for our needs. However, it's good to be aware that provider tools exist for rapid prototyping or if they fit your business need. 

## How does an LLM use tools? 

So how can an LLM, that generates text based on probabilities, actually select and execute a tool? This is made possible by a feature called **Tool Calling**. We are able to define tools via structured descriptions that tell the LLM what tools (functions, APIs or actions) are available, what parameters they expect and what they do. Once the LLM receives this information, it can reason about which tool may be appropriate for a given task and how to use it, purely through text generation. If the LLM decides to use a tool, it generates a tool call; a structured output that includes the name of the tool and the arguments required to invoke it. This tool call is passed to an external executor, which actually runs the tool with the arguments in the real world (i.e. our code). 

## How tool calling works

Tool calling is a multi-step process. It starts with the developer sending the users prompt along with tool definitions to the LLM. Note: the LLM itself **does not** execute the tool(s) itself, it generates a textual response indicating which tool (if any) should be called and with what parameters. Think of the LLM like a mediator between the user prompt and the available tools. Our code, will then execute the tool identified by the LLM with the parameters provided also by the LLM. Once the tool has executed, the result is returned to the LLM, along with all prior messages, which then interprets the output and continues to conversation, assessing if a final result can be returned or further tools are required. 

So within our agent, we must: 

1. Define the tool definitions we will provide to the LLM.
2. Define the actual tool implementation.
3. Provide the LLM with the task to perform and toll definitions from step 1.
4. Build a systems that can execute the tools based on the tool call generated by the LLM. 
5. Reflect the execution results back into the LLM's context. 

